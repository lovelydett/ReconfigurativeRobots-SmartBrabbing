{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 1021, 1021, 100)   4900      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1021, 1021, 100)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 255, 255, 100)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 252, 252, 100)     160100    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 252, 252, 100)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 63, 63, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 60, 60, 100)       160100    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 60, 60, 100)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 15, 15, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 22500)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                1125050   \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,450,201\n",
      "Trainable params: 1,450,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#3层卷积\n",
    "imgSize = 1024  #图片是512*512\n",
    "imgChan = 3    #3通道\n",
    "kernelInit = 'uniform'  #卷积核初始化方式\n",
    "nHiddenUnits = 50\n",
    "maxpoolSize = (4,4)\n",
    "nFilters = 100 #130 before \n",
    "kernelSize = (4,4)\n",
    "inputStrides = 1\n",
    "#costFunction = 'categorical_crossentropy' #代价函数:不同于损失函数，代价函数在整个训练集上计算\n",
    "early_stop_delta = 0.01 # 0.01 change or above is considered improvement\n",
    "early_stop_patience = 10 \n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=nFilters, kernel_size = kernelSize ,strides= inputStrides,\n",
    "                 input_shape=(imgSize,imgSize,3),kernel_initializer= kernelInit))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=maxpoolSize))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=nFilters, kernel_size = kernelSize ,strides= inputStrides,\n",
    "                 kernel_initializer= kernelInit))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=maxpoolSize))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=nFilters, kernel_size = kernelSize ,strides= inputStrides,\n",
    "                 kernel_initializer= kernelInit))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=maxpoolSize))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(nHiddenUnits))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid')) #二分类\n",
    "\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=early_stop_delta, patience=early_stop_patience, verbose=2, mode='auto')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义 train_generator:\n",
    "def train_generator():\n",
    "    while 1:\n",
    "        with open(\"../../data/ImgProcessed/training/m/names.txt\") as file:\n",
    "            for line in file.readlines():\n",
    "                img = Image.open(\"../../data/ImgProcessed/training/m/\"+line.strip(\"\\n\"))\n",
    "                img = img.resize((imgSize,imgSize))\n",
    "                #print(model.predict(np.array(img).reshape((1,imgSize,imgSize,3))))\n",
    "                yield (np.array(img).reshape((1,imgSize,imgSize,3))/255,np.ones((1,1)))\n",
    "                #1是煤\n",
    "                #imgs.append(img)\n",
    "        with open(\"../../data/ImgProcessed/training/s/names.txt\") as file:\n",
    "            for line in file.readlines():\n",
    "                img = Image.open(\"../../data/ImgProcessed/training/s/\"+line.strip(\"\\n\"))\n",
    "                img = img.resize((imgSize,imgSize))\n",
    "                #print(model.predict(np.array(img).reshape((1,imgSize,imgSize,3))))\n",
    "                yield (np.array(img).reshape((1,imgSize,imgSize,3))/255,np.zeros((1,1)))\n",
    "                #0是煤矸石\n",
    "                #imgs.append(img)\n",
    "def validation_generator():\n",
    "    while 1:\n",
    "        with open(\"../../data/ImgProcessed/validation/m/names.txt\") as file:\n",
    "            for line in file.readlines():\n",
    "                img = Image.open(\"../../data/ImgProcessed/validation/m/\"+line.strip(\"\\n\"))\n",
    "                img = img.resize((imgSize,imgSize))\n",
    "                yield (np.array(img).reshape((1,imgSize,imgSize,3))/255,np.ones((1,1)))\n",
    "                #1是煤\n",
    "        with open(\"../../data/ImgProcessed/validation/s/names.txt\") as file:\n",
    "            for line in file.readlines():\n",
    "                img = Image.open(\"../../data/ImgProcessed/validation/s/\"+line.strip(\"\\n\"))\n",
    "                img = img.resize((imgSize,imgSize))\n",
    "                yield (np.array(img).reshape((1,imgSize,imgSize,3))/255,np.zeros((1,1)))\n",
    "                #0是煤矸石"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.8        0.83529412 0.81568627]\n",
      "   [0.80392157 0.83921569 0.81960784]\n",
      "   [0.80784314 0.84313725 0.82352941]\n",
      "   ...\n",
      "   [0.7254902  0.75294118 0.72156863]\n",
      "   [0.7254902  0.75294118 0.72156863]\n",
      "   [0.72941176 0.75686275 0.7254902 ]]\n",
      "\n",
      "  [[0.8        0.83529412 0.81568627]\n",
      "   [0.80392157 0.83921569 0.81960784]\n",
      "   [0.80392157 0.83921569 0.81960784]\n",
      "   ...\n",
      "   [0.7254902  0.75294118 0.72156863]\n",
      "   [0.7254902  0.75294118 0.72156863]\n",
      "   [0.72941176 0.75686275 0.7254902 ]]\n",
      "\n",
      "  [[0.8        0.83529412 0.81568627]\n",
      "   [0.80392157 0.83921569 0.81960784]\n",
      "   [0.79607843 0.83137255 0.81176471]\n",
      "   ...\n",
      "   [0.7254902  0.75294118 0.72156863]\n",
      "   [0.7254902  0.75294118 0.72156863]\n",
      "   [0.72941176 0.75686275 0.7254902 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.74901961 0.77647059 0.74901961]\n",
      "   [0.74901961 0.77647059 0.74901961]\n",
      "   [0.74509804 0.77254902 0.74509804]\n",
      "   ...\n",
      "   [0.71764706 0.74509804 0.71764706]\n",
      "   [0.71764706 0.74509804 0.71764706]\n",
      "   [0.72156863 0.74901961 0.72156863]]\n",
      "\n",
      "  [[0.74901961 0.77647059 0.74901961]\n",
      "   [0.74901961 0.77647059 0.74901961]\n",
      "   [0.74509804 0.77254902 0.74509804]\n",
      "   ...\n",
      "   [0.72156863 0.74901961 0.72156863]\n",
      "   [0.72156863 0.74901961 0.72156863]\n",
      "   [0.71764706 0.74509804 0.71764706]]\n",
      "\n",
      "  [[0.74901961 0.77647059 0.74901961]\n",
      "   [0.74901961 0.77647059 0.74901961]\n",
      "   [0.74509804 0.77254902 0.74509804]\n",
      "   ...\n",
      "   [0.72156863 0.74901961 0.72156863]\n",
      "   [0.72156863 0.74901961 0.72156863]\n",
      "   [0.71372549 0.74117647 0.71372549]]]]\n"
     ]
    }
   ],
   "source": [
    "test = train_generator()\n",
    "x,y = test.__next__()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25/25 [==============================] - 158s 6s/step - loss: 1.1921e-07 - binary_accuracy: 1.0000 - val_loss: 7.1517 - val_binary_accuracy: 0.5514\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 158s 6s/step - loss: 1.1921e-07 - binary_accuracy: 1.0000 - val_loss: 7.1517 - val_binary_accuracy: 0.5514\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 156s 6s/step - loss: 1.1921e-07 - binary_accuracy: 1.0000 - val_loss: 8.4927 - val_binary_accuracy: 0.4673\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 159s 6s/step - loss: 1.1921e-07 - binary_accuracy: 1.0000 - val_loss: 8.7907 - val_binary_accuracy: 0.4486\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 149s 6s/step - loss: 0.6377 - binary_accuracy: 0.9600 - val_loss: 7.7477 - val_binary_accuracy: 0.5140\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08),loss=\"binary_crossentropy\",metrics=['binary_accuracy'])\n",
    "history = model.fit_generator(train_generator(),steps_per_epoch=25,epochs=5,validation_data=validation_generator(),validation_steps=107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
