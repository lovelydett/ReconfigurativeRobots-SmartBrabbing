{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Activation,Dropout,Flatten,Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\n",
    "from PIL import Image,ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" #Titan XP\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess = tf.Session(config=config)\n",
    "imgSize = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/prj201904037/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/prj201904037/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/prj201904037/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/prj201904037/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/prj201904037/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/prj201904037/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/prj201904037/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/prj201904037/miniconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/prj201904037/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                983070    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 15,697,789\n",
      "Trainable params: 15,697,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#加载检测模型\n",
    "detect_model = keras.models.load_model(\"../../model/DETECT_VGG16_256_hid30_epoch10.h5\")\n",
    "detect_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 16, 16, 512)       14714688  \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 50)                6553650   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 21,268,389\n",
      "Trainable params: 21,268,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#加载识别模型\n",
    "recognize_model = keras.models.load_model(\"../../model/Recog_RGB_VGG16_512_h50_epoch10.h5\")\n",
    "recognize_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#①分割：用opencv读取进来进行处理，然后进行增强，然后进行分割，分割结果转换为PIL图片\n",
    "#注意cv2用的是BGR，PIL用的是RGB\n",
    "def segmentation(origin_img):\n",
    "    \n",
    "#   复制边缘进行padding\n",
    "    #origin_img = cv2.copyMakeBorder(origin_img,100,100,100,100,cv2.BORDER_REPLICATE)   \n",
    "#     M=np.ones(origin_img.shape,dtype='uint8')*20\n",
    "#     origin_img=cv2.subtract(origin_img,M)\n",
    "    origin_img = cv2.copyMakeBorder(origin_img,20,20,20,20,cv2.BORDER_CONSTANT,value=(220,220,220))   \n",
    "    img = origin_img.copy()\n",
    "    \n",
    "    \n",
    "#   增亮度\n",
    "#     M=np.ones(img.shape,dtype='uint8')*80\n",
    "#     img=cv2.add(M,img)\n",
    "\n",
    "#   转灰度\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #gray = cv2.equalizeHist(gray)\n",
    "    #gray = cv2.normalize(gray,dst=None,alpha=350,beta=10,norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "    \n",
    "    # #先获取白色背景\n",
    "\n",
    "    # gray_values = []\n",
    "    # for i in range(gray.shape[0]):\n",
    "    #     for j in range(gray.shape[1]):\n",
    "    #         gray_values.append(gray[i][j])\n",
    "    # gray_values.sort()\n",
    "    # mid_value = gray_values[int(len(gray_values)/2)]\n",
    "    # print(mid_value)\n",
    "\n",
    "    # for i in range(gray.shape[0]):\n",
    "    #     for j in range(gray.shape[1]):\n",
    "    #         if gray[i][j]>mid_value:\n",
    "    #             gray[i][j] = 255\n",
    "    #         else:\n",
    "    #             gray[i][j] = 0\n",
    "\n",
    "    #转灰度 高糊\n",
    "    img = cv2.GaussianBlur(img, (9, 9),0) \n",
    "    ret,blurred = cv2.threshold(img, 0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    img = cv2.GaussianBlur(img, (9, 9),0) \n",
    "    ret,img = cv2.threshold(img, 0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    img = cv2.GaussianBlur(img, (9, 9),0) \n",
    "    ret,img = cv2.threshold(img, 0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    #plt.imshow(img)\n",
    "\n",
    "    # #提取梯度\n",
    "    # gradX = cv2.Sobel(blurred, ddepth=cv2.CV_32F, dx=1, dy=0)\n",
    "    # gradY = cv2.Sobel(blurred, ddepth=cv2.CV_32F, dx=0, dy=1)\n",
    "\n",
    "    # gradient = cv2.subtract(gradX, gradY)\n",
    "    # gradient = cv2.convertScaleAbs(gradient)\n",
    "\n",
    "    # plt.imshow(gradient)\n",
    "\n",
    "\n",
    "    #blurred = cv2.GaussianBlur(gradient, (9, 9),0)\n",
    "    #(_, img) = cv2.threshold(img, 0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    #plt.imshow(thresh)\n",
    "\n",
    "    #腐蚀膨胀的核\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    #plt.imshow(closed)\n",
    "\n",
    "    #腐蚀膨胀\n",
    "    img = cv2.erode(img, None, iterations=2)\n",
    "    img = cv2.dilate(img, None, iterations=2)\n",
    "    #plt.imshow(closed)\n",
    "\n",
    "    #分割\n",
    "    (_,contours,_) = cv2.findContours(img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE,)\n",
    "    #print(len(contours))\n",
    "\n",
    "    #在原图上裁出分割结果\n",
    "    segments = []\n",
    "    best_contours = []\n",
    "    for c in contours:\n",
    "        #todo:阈值选取更加合理一点\n",
    "        if cv2.arcLength(c, True) >500 and cv2.arcLength(c, True) < 5000 :\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            crop_img= origin_img[y:y+h, x:x+w]\n",
    "            #cv2.imwrite('../../data/imgNew/imgFromSeg/'+str(count)+\".jpg\",crop_img) \n",
    "            \n",
    "            #转为PIL图片\n",
    "            crop_img = Image.fromarray(cv2.cvtColor(crop_img,cv2.COLOR_BGR2RGB))\n",
    "            segments.append(crop_img)\n",
    "            best_contours.append(c)\n",
    "    return segments,best_contours,origin_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#②分类\n",
    "#判断为煤返回m，煤矸石返回s，其他返回n\n",
    "def recognize(img):\n",
    "    img = img.filter(ImageFilter.RankFilter(5, 8))\n",
    "    img2 = img.copy()\n",
    "    img2 = img2.resize((256,256),Image.ANTIALIAS)\n",
    "    #img = img.filter(ImageFilter.EDGE_ENHANCE)\n",
    "    #img = img.filter(ImageFilter.DETAIL)\n",
    "    isObject = detect_model.predict(np.array(img2).reshape((1,256,256,3))/255)[0]\n",
    "    #是煤或煤矸石\n",
    "    if isObject>=0.5:\n",
    "        img = img.resize((imgSize,imgSize),Image.ANTIALIAS)\n",
    "        pred_value = recognize_model.predict(np.array(img).reshape((1,imgSize,imgSize,3))/255)[0]\n",
    "        return 'm' if pred_value<0.5 else 's'\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple test\n",
    "segments,contours,origin_img = segmentation(\"../../data/scene/(1).jpg\")\n",
    "for i in range(len(segments)):\n",
    "    ret = recognize(segments[i])\n",
    "    (x, y, w, h) = cv2.boundingRect(contours[i])\n",
    "    if ret == 'm':\n",
    "        cv2.rectangle(origin_img, (x, y), (x+w, y+h), (255, 0, 0), 8)\n",
    "    elif ret == 's':\n",
    "        cv2.rectangle(origin_img, (x, y), (x+w, y+h), (0,0 , 255), 8)\n",
    "    else:\n",
    "        cv2.rectangle(origin_img, (x, y), (x+w, y+h), (0,255 ,0 ), 8)\n",
    "cv2.imwrite(\"test.jpg\",origin_img)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 1 ,seg: 0.7389129999974102 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prj201904037/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "/home/prj201904037/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/prj201904037/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognize: 11.999979000000167\n",
      "frame 2 ,seg: 0.6869079999996757 recognize: 12.538712000001397\n",
      "frame 3 ,seg: 0.5543030000008002 recognize: 12.753002000001288\n",
      "frame 4 ,seg: 0.6605230000022857 recognize: 12.444503999999142\n",
      "frame 5 ,seg: 0.6763879999998608 recognize: 12.237742999997863\n",
      "frame 6 ,seg: 1.0151939999996102 recognize: 12.723698000001605\n",
      "frame 7 ,seg: 1.0457050000004529 recognize: 12.311934000001202\n",
      "frame 8 ,seg: 1.0083979999981239 recognize: 12.580312000001868\n",
      "frame 9 ,seg: 0.959285999997519 recognize: 12.19506100000217\n",
      "frame 10 ,seg: 0.8703069999974105 recognize: 12.862837000000582\n",
      "frame 11 ,seg: 0.5603359999986424 recognize: 12.33994900000107\n",
      "frame 12 ,seg: 0.7584360000000743 recognize: 11.999874000001\n",
      "frame 13 ,seg: 0.783966999999393 recognize: 12.83930799999871\n",
      "frame 14 ,seg: 1.086008000002039 recognize: 10.602590999998938\n",
      "frame 15 ,seg: 0.7178960000019288 recognize: 12.542742999998154\n",
      "frame 16 ,seg: 0.7144799999987299 recognize: 12.706994000000122\n",
      "frame 17 ,seg: 0.965052999999898 recognize: 11.662538000000495\n",
      "frame 18 ,seg: 1.1719300000004296 recognize: 11.7245010000006\n",
      "frame 19 ,seg: 0.6105809999971825 recognize: 12.892240000001038\n",
      "frame 20 ,seg: 1.0066159999987576 recognize: 12.666316999999253\n",
      "frame 21 ,seg: 1.055545000002894 recognize: 12.258491000000504\n",
      "frame 22 ,seg: 0.9457409999995434 recognize: 11.878154000001814\n",
      "frame 23 ,seg: 0.936744999999064 recognize: 13.09373400000186\n",
      "frame 24 ,seg: 1.5496190000012575 recognize: 12.452966000000742\n",
      "frame 25 ,seg: 0.6956669999999576 recognize: 13.482046000000992\n",
      "frame 26 ,seg: 0.6563759999989998 recognize: 11.652609000000666\n",
      "frame 27 ,seg: 1.1481669999993755 recognize: 12.92877000000226\n",
      "frame 28 ,seg: 0.7800700000007055 recognize: 12.46811499999967\n",
      "frame 29 ,seg: 0.7060290000008536 recognize: 12.672387999999046\n",
      "frame 30 ,seg: 1.0155420000010054 recognize: 12.9650049999982\n",
      "frame 31 ,seg: 1.211949000000459 recognize: 13.627056000001176\n",
      "frame 32 ,seg: 1.7394050000002608 recognize: 13.434124000003067\n",
      "frame 33 ,seg: 0.8529399999970337 recognize: 12.752039000002696\n",
      "frame 34 ,seg: 0.8028369999992719 recognize: 13.003324000001157\n",
      "frame 35 ,seg: 1.1264959999971325 recognize: 12.797524000001431\n",
      "frame 36 ,seg: 1.1578069999995932 recognize: 13.462767000000895\n",
      "frame 37 ,seg: 0.7287079999987327 recognize: 12.028751999998349\n",
      "frame 38 ,seg: 0.7476949999982025 recognize: 12.487335000001622\n",
      "frame 39 ,seg: 0.8553309999988414 recognize: 12.6381020000008\n",
      "frame 40 ,seg: 0.6223810000010417 recognize: 13.234507000001031\n",
      "frame 41 ,seg: 1.0349889999997686 recognize: 12.9759120000017\n",
      "frame 42 ,seg: 1.1524439999993774 recognize: 12.135827999998583\n",
      "frame 43 ,seg: 0.7806349999991653 recognize: 13.366851999999199\n",
      "frame 44 ,seg: 0.5160990000003949 recognize: 12.376193000000058\n",
      "frame 45 ,seg: 0.7829759999985981 recognize: 11.622240000000602\n",
      "frame 46 ,seg: 0.7414879999996629 recognize: 12.324316000002\n",
      "frame 47 ,seg: 0.8047630000000936 recognize: 13.094493999997212\n",
      "frame 48 ,seg: 0.8020729999989271 recognize: 12.322417999999743\n",
      "frame 49 ,seg: 0.8526249999995343 recognize: 13.017047000001185\n",
      "frame 50 ,seg: 1.0109499999998661 recognize: 13.334876000000804\n",
      "frame 51 ,seg: 1.0103999999992084 recognize: 13.036760999999387\n",
      "frame 52 ,seg: 0.7109539999983099 recognize: 12.198997999999847\n",
      "frame 53 ,seg: 1.3944480000027397 recognize: 12.890325999997003\n",
      "frame 54 ,seg: 0.6660249999986263 recognize: 11.772134000002552\n",
      "frame 55 ,seg: 0.8603199999997742 recognize: 11.16264599999704\n",
      "frame 56 ,seg: 0.7046310000005178 recognize: 11.292883999998594\n",
      "frame 57 ,seg: 1.1475099999988743 recognize: 12.303208999997878\n",
      "frame 58 ,seg: 0.8344370000013441 recognize: 12.103671000000759\n",
      "frame 59 ,seg: 1.13811799999894 recognize: 11.851814999998169\n",
      "frame 60 ,seg: 0.6980870000006689 recognize: 13.625583999997616\n",
      "frame 61 ,seg: 1.0554630000006 recognize: 13.593268999997235\n",
      "frame 62 ,seg: 0.7756790000021283 recognize: 13.340207999997801\n",
      "frame 63 ,seg: 0.928779999998369 recognize: 13.221242999999959\n",
      "frame 64 ,seg: 0.4922119999973802 recognize: 13.023317999999563\n",
      "frame 65 ,seg: 0.9839859999992768 recognize: 13.320277000002534\n",
      "frame 66 ,seg: 0.5040880000015022 recognize: 12.279754999999568\n",
      "frame 67 ,seg: 0.5536160000010568 recognize: 13.978641000001517\n",
      "frame 68 ,seg: 1.2108149999985471 recognize: 11.78566100000171\n",
      "frame 69 ,seg: 0.7763310000009369 recognize: 13.04472899999746\n",
      "frame 70 ,seg: 0.5572060000013153 recognize: 12.30373999999938\n",
      "frame 71 ,seg: 0.6645320000025094 recognize: 12.30159999999887\n",
      "frame 72 ,seg: 1.500318000002153 recognize: 13.23073999999906\n",
      "frame 73 ,seg: 1.4828589999997348 recognize: 13.095663000000059\n",
      "frame 74 ,seg: 0.7213410000003933 recognize: 14.282153000000108\n",
      "frame 75 ,seg: 1.2425070000026608 recognize: 14.05160099999921\n",
      "frame 76 ,seg: 0.7905579999969632 recognize: 13.502546000003349\n",
      "frame 77 ,seg: 1.0445739999995567 recognize: 13.614971999999398\n",
      "frame 78 ,seg: 1.2091809999983525 recognize: 13.377963999999338\n",
      "frame 79 ,seg: 0.976278000001912 recognize: 12.479596000001038\n",
      "frame 80 ,seg: 0.6903019999990647 recognize: 13.211429999999382\n",
      "frame 81 ,seg: 0.6701289999982691 recognize: 12.967918999998801\n",
      "frame 82 ,seg: 0.952473999997892 recognize: 12.440381000000343\n",
      "frame 83 ,seg: 0.9571760000035283 recognize: 13.732764999997016\n",
      "frame 84 ,seg: 1.0679529999979422 recognize: 13.026625999998942\n",
      "frame 85 ,seg: 0.7093710000008286 recognize: 12.318409999999858\n",
      "frame 86 ,seg: 0.9536140000018349 recognize: 11.818038999997952\n",
      "frame 87 ,seg: 0.8241399999969872 recognize: 12.47250300000087\n",
      "frame 88 ,seg: 0.6272869999993418 recognize: 13.9403999999995\n",
      "frame 89 ,seg: 0.7799190000005183 recognize: 14.007337999999436\n",
      "frame 90 ,seg: 1.063837000001513 recognize: 14.255096999997477\n",
      "frame 91 ,seg: 0.7424410000021453 recognize: 12.59737899999891\n",
      "frame 92 ,seg: 0.686611000000994 recognize: 12.9564790000004\n",
      "frame 93 ,seg: 0.9800299999988056 recognize: 13.404237999999168\n",
      "frame 94 ,seg: 1.1820860000007087 recognize: 14.074851000001217\n",
      "frame 95 ,seg: 0.7128259999990405 recognize: 12.767641999998887\n",
      "frame 96 ,seg: 0.9341300000014598 recognize: 13.697250999997777\n",
      "frame 97 ,seg: 0.8926009999995586 recognize: 13.205668999999034\n",
      "frame 98 ,seg: 0.8006969999987632 recognize: 14.344262999999046\n",
      "frame 99 ,seg: 1.0687870000001567 recognize: 13.648863999998866\n",
      "frame 100 ,seg: 0.8920010000001639 recognize: 13.743070000000444\n",
      "frame 101 ,seg: 0.5863140000001295 recognize: 12.30483599999934\n"
     ]
    }
   ],
   "source": [
    "#video process\n",
    "#读取视频中每一帧，依次处理\n",
    "cap = cv2.VideoCapture(\"../../data/video/WIN_20191109_14_51_12_Pro.mp4\")\n",
    "fps = 20\n",
    "size = (640, 480)\n",
    "out = cv2.VideoWriter(\"../../data/video/video_processed/output3.avi\", cv2.VideoWriter_fourcc('D', 'I', 'V', 'X') , fps, size)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "count = 0\n",
    "while count<=100 and ret:  \n",
    "    count+=1\n",
    "    print(\"frame\",count,end = \" ,\")\n",
    "    start = time.clock()\n",
    "    segments,contours,frame = segmentation(frame)\n",
    "    seg_end = time.clock()\n",
    "    print(\"seg:\",seg_end-start,end = ' ')\n",
    "    for i in range(len(segments)):\n",
    "        ret = recognize(segments[i])\n",
    "        (x, y, w, h) = cv2.boundingRect(contours[i])\n",
    "        if ret == 'm':\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 8)\n",
    "        elif ret == 's':\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0,0 , 255), 8)\n",
    "        else:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255 ,0 ), 8)\n",
    "    rec_end = time.clock()\n",
    "    print(\"recognize:\",rec_end-seg_end)\n",
    "    out.write(frame)\n",
    "    ret,frame = cap.read()\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
